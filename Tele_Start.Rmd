---
title: "HW2 Telemarketing"
author: "Patrick Barringer"
date: "11/2/2020"
output:
  html_document:
    toc: true
    theme: readable
    highlight: tango
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Downloading and Prepping the Data

```{r, cache=TRUE}
#Downloading and Prepping the Data
tele <- read.csv(file = "tele.csv", stringsAsFactors = TRUE)
summary(tele)

#We are deleting the "duration" variable because it is an after the fact measurement. We only should be using variables that we know before the call
tele$duration <- NULL

# Deleting the column X
tele$X <- NULL

# Changing pdays to a dummy and deleting pdays
tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1)
tele$pdays <- NULL

str(tele)
```

## Getting Data Ready for Analysis

```{r, cache=TRUE}
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into ANN has to be numeric

telemm <- as.data.frame(model.matrix(~.-1,tele))
str(telemm)

# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
tele_random <- telemm[sample(nrow(telemm)),]

#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# we are going to normalize everything 
tele_norm <- as.data.frame(lapply(tele_random, normalize))
summary(tele_norm)

```


## Getting Train and Test Samples

```{r, cache=TRUE}
# Selects 10000 random rows for test data
set.seed(12345)
test_set <- sample(1:nrow(tele_norm), 10000) 
# Depending on R-version and computer, different rows may be selected. 
# If that happens, results are different. 

# Create a train set and test set
#First the predictors - all columns except the yyes column
tele_train <- tele_norm[-test_set, ]
tele_test <- tele_norm[test_set, ]
```

> Now you are ready to build your ANN model. Feel free to modify the data load, cleaning and preparation code above as per your preference.


## Logistic Regression Models:

```{r, cache=TRUE}
library(caret)

#Initial attempt at LR model using all available variables:
lr1 <- glm(yyes ~., data = tele_train, family = binomial(link="logit"))

summary(lr1)

#From the summary, we can tell we are including many insignificant variables

```

### Stepwise Regression to refine our Logistic Regression model to focus on significant variables:

```{r, cache=TRUE}

#Creating the refined model:
stepmodel <- step(lr1, direction = "backward", trace = FALSE)
summary(stepmodel)

#Setting up evaluative matrix using 15% as the necessary prediction level to classify a call as a "Yes" to align with the test
#data's rate of "yes" responses received:
pred_step <- predict(stepmodel, tele_test, type="response")
pred_cat <- ifelse(pred_step >= 0.15, 1, 0)

tele_test$pred <- ifelse(pred_step >= .15, 1, 0)
tele_test$pred <- as.factor(tele_test$pred)

str(tele_test$pred)
str(as.factor(tele_test$yyes))
```

```{r, cache=TRUE}
#Evaluative Matrix:
confusionMatrix(tele_test$pred, as.factor(tele_test$yyes), positive = "1")


```


## ANN Models:

```{r, cache=TRUE}
#Model 1: Initial ANN model using a number of variables selected in an ad hoc manner:

library(neuralnet)
ann1 <- neuralnet(formula = yyes ~ age + jobadmin. + jobblue.collar + jobentrepreneur + jobhousemaid + jobmanagement + jobretired + jobself.employed + jobservices + jobstudent + jobtechnician + jobunemployed + jobunknown + maritalmarried + maritalsingle + maritalunknown + educationbasic.6y + educationbasic.9y + educationhigh.school + educationilliterate + educationprofessional.course + educationuniversity.degree + educationunknown, data = tele_train)

# obtain model results
ann1_results <- compute(ann1, tele_test[-53])

# obtain predicted strength values
predicted_yes <- ifelse(ann1_results$net.result >.15, 1, 0)
head(predicted_yes)
# examine the correlation between predicted and actual values

cor(predicted_yes, as.numeric(tele_test$yyes))


#Model 2: ANN model created using significant variables identified in our logistic regression step model:

ann2 <- neuralnet(formula = yyes ~ jobblue.collar + jobretired + jobservices + 
    jobstudent + maritalsingle + educationbasic.6y + educationuniversity.degree + 
    defaultunknown + contacttelephone + monthaug + monthdec + 
    monthjun + monthmar + monthmay + monthnov + day_of_weekmon + 
    day_of_weekthu + day_of_weekwed + campaign + poutcomenonexistent + 
    poutcomesuccess + emp.var.rate + cons.price.idx + cons.conf.idx + 
    euribor3m + nr.employed + pdaysdummy, data = tele_train)

# obtain model results
ann2_results <- compute(ann2, tele_test[-53])

# obtain predicted strength values
predicted_yes2 <- ifelse(ann2_results$net.result >.15, 1, 0)
head(predicted_yes2)
# examine the correlation between predicted and actual values

cor(predicted_yes2, as.numeric(tele_test$yyes))



```
## Conclusion:

If I am focusing on improving the effectiveness of the telemarketing efforts, I would prefer to leverage the logistical regression model because of transparency of the significant variables. The logistical regression model can tell me which variables are most significant in terms of predicting a positive response rate whereas the ANN model does not provide insights that I, as a manager of the telemarketing efforts, can readily take advantage of. Since the model is unable to execute the telemarketing efforts, accuracy matters less to me than the insights the model provides me with. With more time, I believe the ANN model could likely yield more accurate predictive results, yet they would be hard to leverage into executable strategies for improving the telemarketing efforts. 
